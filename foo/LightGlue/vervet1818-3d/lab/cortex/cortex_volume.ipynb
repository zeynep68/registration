{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/p/fastdata/pli/Private/oberstrass1/datasets/vervet1818-3d\n",
      "jrlogin08.jureca\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%cd ../../\n",
    "\n",
    "!hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import re\n",
    "\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import imageio\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pli\n",
    "import pli.image as im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Build volume\n",
    "\n",
    "WM = 1\n",
    "GM = 2\n",
    "BG = 3\n",
    "\n",
    "# Get section info\n",
    "\n",
    "cortex_path = \"data/aa/masks/cortex/\"\n",
    "\n",
    "# Pyramid level to build volume with\n",
    "data_group = 'volume'\n",
    "pyramid = 4\n",
    "class_mapping = {WM: 200, GM: 100, BG: 0} # {WM: 200, GM: 100, BG: 0}, pial: {WM: True, GM: True, BG: False}, wm: {WM: True, GM: False, BG: False}\n",
    "dtype =  np.uint8 # np.uint8, np.bool\n",
    "chunks = (1, 256, 256)  # (1, 256, 256)\n",
    "section_thickness = 60  # mu\n",
    "compression ='gzip'\n",
    "\n",
    "out_file = f\"data/aa/volume/cortex/cortex_{pyramid}.h5\"\n",
    "\n",
    "###\n",
    "\n",
    "sections = []\n",
    "p = re.compile('.*s([0-9]{4})_.*')\n",
    "for f in os.listdir(cortex_path):\n",
    "    id = int(p.match(f)[1])\n",
    "    sections.append({'id': id, 'file': f})\n",
    "\n",
    "sections_df = pd.DataFrame(sections).sort_values('id').reset_index(drop=True)\n",
    "\n",
    "z_min = sections_df.id.min()\n",
    "z_max = sections_df.id.max()\n",
    "z_stacks = z_max - z_min + 1\n",
    "missing = sorted(set(np.arange(z_min, z_max)).difference(set(sections_df.id)))\n",
    "\n",
    "print(\"Missing\", missing)\n",
    "sections_df.head()\n",
    "\n",
    "with h5.File(out_file, 'w') as f:\n",
    "    print(\"Create H5 File\")\n",
    "    cur_section = pli.data.Section(os.path.join(cortex_path, sections_df.file[0]))\n",
    "\n",
    "    # Determine spacing of the volume (z, y, x)\n",
    "    out_spacing = (section_thickness, (2 ** pyramid) * cur_section.spacing[0], (2 ** pyramid) * cur_section.spacing[1])\n",
    "    print(f\"Volume spacing:\\t{out_spacing}\")\n",
    "\n",
    "    # Determine output shape of the volume (z, y, x)\n",
    "    out_shape = (z_stacks, *cur_section.pyramid[pyramid].shape)\n",
    "    print(f\"Volume shape:\\t{out_shape}\")\n",
    "\n",
    "    affine = np.eye(4)[:3] * np.array(out_spacing)[None].T\n",
    "    f['affine'] = affine\n",
    "\n",
    "    # Create empty dataset\n",
    "    v_ds = f.create_dataset(\n",
    "        name=data_group,\n",
    "        shape=out_shape,\n",
    "        dtype=dtype,\n",
    "        chunks=chunks,\n",
    "        compression=compression,\n",
    "    )\n",
    "    v_ds.attrs['spacing'] = out_spacing\n",
    "    v_ds.attrs['BG'] = class_mapping[BG]\n",
    "    v_ds.attrs['GM'] = class_mapping[GM]\n",
    "    v_ds.attrs['WM'] = class_mapping[WM]\n",
    "\n",
    "    print(\"Write masks to volume...\")\n",
    "    for k, r in tqdm(sections_df.iterrows(), total=len(sections_df)):\n",
    "        # Load mask from disk\n",
    "        mask = cur_section.pyramid[pyramid][:]\n",
    "\n",
    "        # Map class indices to their values\n",
    "        mask = np.vectorize(class_mapping.get, otypes=[dtype])(mask)\n",
    "\n",
    "        # Write mask to volume\n",
    "        z_ix = r.id - z_min\n",
    "        v_ds[z_ix] = mask\n",
    "\n",
    "        if k in sections_df.index:\n",
    "            cur_section = pli.data.Section(os.path.join(cortex_path, sections_df.file[k]))\n",
    "\n",
    "    print(\"Infer missing masks...\")\n",
    "    for m in tqdm(missing):\n",
    "        # Get two closes sections to infer values from\n",
    "        close = sections_df.iloc[(sections_df.id - m).abs().argsort()[:2]].id.values\n",
    "        ix_1 = close[0] - z_min\n",
    "        mask_1 = v_ds[ix_1][:]\n",
    "        ix_2 = close[1] - z_min\n",
    "        mask_2 = v_ds[ix_2][:]\n",
    "        print(f\"Infer mask between {close[0]}({ix_1}) and {close[1]}({ix_2})\")\n",
    "\n",
    "        # Interpolate mask by next to neighbors\n",
    "        #mask_inter = np.full_like(mask_1, class_mapping[GM], dtype=dtype)\n",
    "        mask_inter = mask_1\n",
    "        mask_inter[mask_2 == class_mapping[GM]] = class_mapping[GM]\n",
    "\n",
    "        # Write mask to volume\n",
    "        z_ix = m - z_min\n",
    "        v_ds[z_ix] = mask_inter\n",
    "\n",
    "        sections_df = sections_df.append(pd.DataFrame([{'id': m, 'file': None}]), ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Venv (pli-env)",
   "language": "python",
   "name": "pli-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
